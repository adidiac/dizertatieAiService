{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.880184331797235,
  "eval_steps": 500,
  "global_step": 2500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0576036866359447,
      "grad_norm": 1.1788772344589233,
      "learning_rate": 4.905913978494624e-05,
      "loss": 0.0836,
      "step": 50
    },
    {
      "epoch": 0.1152073732718894,
      "grad_norm": 1.4238497018814087,
      "learning_rate": 4.8099078341013826e-05,
      "loss": 0.0698,
      "step": 100
    },
    {
      "epoch": 0.1728110599078341,
      "grad_norm": 0.9708845615386963,
      "learning_rate": 4.7139016897081415e-05,
      "loss": 0.0614,
      "step": 150
    },
    {
      "epoch": 0.2304147465437788,
      "grad_norm": 0.4672670364379883,
      "learning_rate": 4.6178955453149e-05,
      "loss": 0.0579,
      "step": 200
    },
    {
      "epoch": 0.2880184331797235,
      "grad_norm": 0.9893795847892761,
      "learning_rate": 4.52188940092166e-05,
      "loss": 0.058,
      "step": 250
    },
    {
      "epoch": 0.3456221198156682,
      "grad_norm": 1.269235372543335,
      "learning_rate": 4.425883256528418e-05,
      "loss": 0.0575,
      "step": 300
    },
    {
      "epoch": 0.4032258064516129,
      "grad_norm": 1.3433945178985596,
      "learning_rate": 4.329877112135177e-05,
      "loss": 0.0577,
      "step": 350
    },
    {
      "epoch": 0.4608294930875576,
      "grad_norm": 0.8637337684631348,
      "learning_rate": 4.2338709677419356e-05,
      "loss": 0.0536,
      "step": 400
    },
    {
      "epoch": 0.5184331797235023,
      "grad_norm": 1.0743744373321533,
      "learning_rate": 4.1378648233486944e-05,
      "loss": 0.0562,
      "step": 450
    },
    {
      "epoch": 0.576036866359447,
      "grad_norm": 0.7531309127807617,
      "learning_rate": 4.041858678955453e-05,
      "loss": 0.0548,
      "step": 500
    },
    {
      "epoch": 0.6336405529953917,
      "grad_norm": 0.6582635045051575,
      "learning_rate": 3.945852534562212e-05,
      "loss": 0.0508,
      "step": 550
    },
    {
      "epoch": 0.6912442396313364,
      "grad_norm": 0.7587073445320129,
      "learning_rate": 3.849846390168971e-05,
      "loss": 0.0531,
      "step": 600
    },
    {
      "epoch": 0.7488479262672811,
      "grad_norm": 0.625687837600708,
      "learning_rate": 3.75384024577573e-05,
      "loss": 0.0544,
      "step": 650
    },
    {
      "epoch": 0.8064516129032258,
      "grad_norm": 0.886893093585968,
      "learning_rate": 3.6578341013824886e-05,
      "loss": 0.0502,
      "step": 700
    },
    {
      "epoch": 0.8640552995391705,
      "grad_norm": 0.48516878485679626,
      "learning_rate": 3.5618279569892474e-05,
      "loss": 0.0505,
      "step": 750
    },
    {
      "epoch": 0.9216589861751152,
      "grad_norm": 0.9466032981872559,
      "learning_rate": 3.465821812596006e-05,
      "loss": 0.051,
      "step": 800
    },
    {
      "epoch": 0.9792626728110599,
      "grad_norm": 0.8803688883781433,
      "learning_rate": 3.369815668202765e-05,
      "loss": 0.0515,
      "step": 850
    },
    {
      "epoch": 1.0368663594470047,
      "grad_norm": 0.33582210540771484,
      "learning_rate": 3.273809523809524e-05,
      "loss": 0.0503,
      "step": 900
    },
    {
      "epoch": 1.0944700460829493,
      "grad_norm": 0.6343708634376526,
      "learning_rate": 3.177803379416283e-05,
      "loss": 0.0473,
      "step": 950
    },
    {
      "epoch": 1.1520737327188941,
      "grad_norm": 0.8187183737754822,
      "learning_rate": 3.0817972350230416e-05,
      "loss": 0.0462,
      "step": 1000
    },
    {
      "epoch": 1.2096774193548387,
      "grad_norm": 0.5702840685844421,
      "learning_rate": 2.9857910906298004e-05,
      "loss": 0.0484,
      "step": 1050
    },
    {
      "epoch": 1.2672811059907834,
      "grad_norm": 0.4082290232181549,
      "learning_rate": 2.8897849462365596e-05,
      "loss": 0.0474,
      "step": 1100
    },
    {
      "epoch": 1.3248847926267282,
      "grad_norm": 0.4582396149635315,
      "learning_rate": 2.793778801843318e-05,
      "loss": 0.0439,
      "step": 1150
    },
    {
      "epoch": 1.3824884792626728,
      "grad_norm": 0.6700665950775146,
      "learning_rate": 2.6977726574500766e-05,
      "loss": 0.0464,
      "step": 1200
    },
    {
      "epoch": 1.4400921658986174,
      "grad_norm": 0.7910655736923218,
      "learning_rate": 2.6017665130568358e-05,
      "loss": 0.0449,
      "step": 1250
    },
    {
      "epoch": 1.4976958525345623,
      "grad_norm": 0.7400940656661987,
      "learning_rate": 2.5057603686635943e-05,
      "loss": 0.0484,
      "step": 1300
    },
    {
      "epoch": 1.555299539170507,
      "grad_norm": 0.4899647831916809,
      "learning_rate": 2.4097542242703534e-05,
      "loss": 0.0454,
      "step": 1350
    },
    {
      "epoch": 1.6129032258064515,
      "grad_norm": 0.6243313550949097,
      "learning_rate": 2.3137480798771123e-05,
      "loss": 0.0464,
      "step": 1400
    },
    {
      "epoch": 1.6705069124423964,
      "grad_norm": 0.9150601029396057,
      "learning_rate": 2.217741935483871e-05,
      "loss": 0.0459,
      "step": 1450
    },
    {
      "epoch": 1.728110599078341,
      "grad_norm": 0.4152182936668396,
      "learning_rate": 2.12173579109063e-05,
      "loss": 0.0457,
      "step": 1500
    },
    {
      "epoch": 1.7857142857142856,
      "grad_norm": 0.8856168389320374,
      "learning_rate": 2.0257296466973888e-05,
      "loss": 0.0459,
      "step": 1550
    },
    {
      "epoch": 1.8433179723502304,
      "grad_norm": 0.2468048632144928,
      "learning_rate": 1.9297235023041476e-05,
      "loss": 0.0427,
      "step": 1600
    },
    {
      "epoch": 1.9009216589861753,
      "grad_norm": 0.37627649307250977,
      "learning_rate": 1.8337173579109064e-05,
      "loss": 0.0437,
      "step": 1650
    },
    {
      "epoch": 1.9585253456221197,
      "grad_norm": 0.8275047540664673,
      "learning_rate": 1.7377112135176653e-05,
      "loss": 0.0431,
      "step": 1700
    },
    {
      "epoch": 2.0161290322580645,
      "grad_norm": 0.7710738778114319,
      "learning_rate": 1.641705069124424e-05,
      "loss": 0.0401,
      "step": 1750
    },
    {
      "epoch": 2.0737327188940093,
      "grad_norm": 0.5129035115242004,
      "learning_rate": 1.545698924731183e-05,
      "loss": 0.0375,
      "step": 1800
    },
    {
      "epoch": 2.1313364055299537,
      "grad_norm": 0.9744616150856018,
      "learning_rate": 1.4496927803379418e-05,
      "loss": 0.0381,
      "step": 1850
    },
    {
      "epoch": 2.1889400921658986,
      "grad_norm": 0.6158688068389893,
      "learning_rate": 1.3536866359447006e-05,
      "loss": 0.0377,
      "step": 1900
    },
    {
      "epoch": 2.2465437788018434,
      "grad_norm": 0.5645036697387695,
      "learning_rate": 1.2576804915514593e-05,
      "loss": 0.0369,
      "step": 1950
    },
    {
      "epoch": 2.3041474654377883,
      "grad_norm": 0.3883284032344818,
      "learning_rate": 1.1616743471582183e-05,
      "loss": 0.0352,
      "step": 2000
    },
    {
      "epoch": 2.3617511520737327,
      "grad_norm": 0.3831499516963959,
      "learning_rate": 1.065668202764977e-05,
      "loss": 0.0367,
      "step": 2050
    },
    {
      "epoch": 2.4193548387096775,
      "grad_norm": 0.6603316068649292,
      "learning_rate": 9.69662058371736e-06,
      "loss": 0.034,
      "step": 2100
    },
    {
      "epoch": 2.476958525345622,
      "grad_norm": 0.43547379970550537,
      "learning_rate": 8.736559139784948e-06,
      "loss": 0.0352,
      "step": 2150
    },
    {
      "epoch": 2.5345622119815667,
      "grad_norm": 0.4701799154281616,
      "learning_rate": 7.776497695852534e-06,
      "loss": 0.0346,
      "step": 2200
    },
    {
      "epoch": 2.5921658986175116,
      "grad_norm": 0.6363502144813538,
      "learning_rate": 6.816436251920123e-06,
      "loss": 0.0375,
      "step": 2250
    },
    {
      "epoch": 2.6497695852534564,
      "grad_norm": 0.8478902578353882,
      "learning_rate": 5.856374807987712e-06,
      "loss": 0.0351,
      "step": 2300
    },
    {
      "epoch": 2.707373271889401,
      "grad_norm": 0.9331639409065247,
      "learning_rate": 4.8963133640553e-06,
      "loss": 0.0378,
      "step": 2350
    },
    {
      "epoch": 2.7649769585253456,
      "grad_norm": 0.49370503425598145,
      "learning_rate": 3.936251920122888e-06,
      "loss": 0.0355,
      "step": 2400
    },
    {
      "epoch": 2.8225806451612905,
      "grad_norm": 0.6113873720169067,
      "learning_rate": 2.9761904761904763e-06,
      "loss": 0.0342,
      "step": 2450
    },
    {
      "epoch": 2.880184331797235,
      "grad_norm": 0.6958112120628357,
      "learning_rate": 2.0161290322580646e-06,
      "loss": 0.0342,
      "step": 2500
    }
  ],
  "logging_steps": 50,
  "max_steps": 2604,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1315064476035072.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
